# from normal distribution
x <- rnorm(1000, mean = 10, sd = 2)
hist(x, breaks = 30, main = "Normal distribution", col = "blue")
# from multivariate normal
mu <- c(5,10)
sigma <- matrix(c(4,2,2,3), nrow=2)
sample = mvrnorm(n=1000, mu=mu,Sigma=sigma)
head(sample)
View(sample)
############Logistic regression
data(iris)
iris_bin= subset(iris, Species!='setosa')
View(iris_bin)
iris$Species <- factor(iris_bin$Species)
iris$Species <- factor(iris_bin$Species)
iris_bin$Species <- factor(iris_bin$Species)
View(iris_bin)
set.seed(1)
train_index<-sample(seq_len(nrow(iris_bin)),size=0.7*nrow(iris_bin))
train_index
nrow(iris_bin)),size=0.7*nrow(iris_bin)
seq_len(nrow(iris_bin))
?seq_len
train_index<-sample( seq_len(nrow(iris_bin)), size=0.7*nrow(iris_bin))
train_data <- iris_bin[sample_idx, ]
train_data <- iris_bin[sample_index, ]
train_data <- iris_bin[train_index, ]
test_data  <- iris_bin[-train_index, ]
model <- glm(Species ~ .,
data = train_data, family = binomial)
summary(model)
pred_prob<-predict(model,newdata = test_data,type='response')
pred_probs_df
pred_prob
pred_class <- ifelse(pred_probs > 0.5, "virginica", "versicolor")
pred_class
View(pred_class)
View(pred_class)
View(pred_class)
View(pred_class)
dim(pred_class)
View(pred_prob)
dim(pred_prob)
length(pred_prob)
pred_prob<-predict(model,newdata = test_data,type='response')
pred_class <- ifelse(pred_probs > 0.5, "virginica", "versicolor")
View(pred_probs)
View(pred_probs)
length(pred_prob)
pred_prob)
pred_prob
dim(pred_class)
actual <- ifelse(test_data$Species == "virginica", 1, 0)
predicted <- ifelse(pred_prob>0.5, 1, 0)
table(Predicted=predicted,Actual=actual)
acc=mean(predicted==actual)
print(acc)
data<- read.csv('/data/example_data.csv')
data<- read.csv('data/example_data.csv')
View(data)
######### Importing data
data<- read.csv('/home/kd/Downloads/AIS_2025_code_session/example_data.csv')
######### Importing data
data<- read.csv('data/example_data.csv')
head(data)
############ 3D plots using plotly
#install.packages("plotly")
library(plotly)
# Sample 3D data (from iris)
plot_ly(data = iris,
x = ~Sepal.Length,
y = ~Petal.Length,
z = ~Sepal.Width,
color = ~Species,
colors = c("red", "green", "blue"),
type = "scatter3d",
mode = "markers",
marker = list(size = 5, opacity = 0.8)) %>%
layout(title = "3D Scatterplot of Iris Data",
scene = list(
xaxis = list(title = 'Sepal Length'),
yaxis = list(title = 'Petal Length'),
zaxis = list(title = 'Sepal Width')
))
# surface plot
x <- seq(-10, 10, length.out = 50)
y <- seq(-10, 10, length.out = 50)
z <- outer(x, y, function(x, y) sin(sqrt(x^2 + y^2)))  # z = sin(sqrt(x² + y²))
View(z)
# Plot the surface
plot_ly(x = ~x, y = ~y, z = ~z) %>%
add_surface(colorscale = 'Viridis') %>%
layout(title = "3D Surface Plot of sin(sqrt(x² + y²))",
scene = list(
xaxis = list(title = "X"),
yaxis = list(title = "Y"),
zaxis = list(title = "Z")
))
####### PCA
data(iris)
iris_numeric <- iris[, 1:4]
pca <- prcomp(iris_numeric, scale. = TRUE)
summary(pca)
biplot(pca, col = c("gray", "red"))
?biplot
set.seed(1)
kmeans_result <- kmeans(iris[, 1:4], centers = 3)
table(kmeans_result$cluster, iris$Species)
# Visualize
library(cluster)
clusplot(iris[, 1:4], kmeans_result$cluster, color = TRUE, shade = TRUE, labels = 2)
?cluster
?clustplot
?clusplot
View(pca)
View(pca)
plot(pca$x[, 1], pca$x[, 2],
col = as.numeric(iris$Species),
pch = 19,
xlab = "PC1",
ylab = "PC2",
main = "PCA: PC1 vs PC2")
legend("topright", legend = levels(iris$Species),
col = 1:3, pch = 19)
plot(pca$x[, 1], pca$x[, 2],
col = as.numeric(iris$Species),
pch = 19,
xlab = "PC1",
ylab = "PC2",
main = "PCA: PC1 vs PC2")
legend("topright", legend = levels(iris$Species),
col = 1:3, pch = 19,cex=0.7)
?prcomp
####### Input, Output statement
var1= readline('Enter a number:')
var2==readline('Enter another number:')
var2=readline('Enter another number:')
print(var1+var2)
var1=as.numeric(var1)
var2=as.numeric(var2)
print(var1+var2)
####### ANOVA
# one way anova
library(dplyr)
head(mtcars)
aov1 <- aov(mtcars$disp~factor(mtcars$gear))
summary(mtcars_aov)
summary(aov1)
# two way anova
# Variance in mean within group and between group
histogram(mtcars$disp~mtcars$gear, subset = (mtcars$am == 0),
xlab = "gear", ylab = "disp", main = "Automatic")
####### ANOVA
# one way anova
library(dplyr)
# two way anova
# Variance in mean within group and between group
histogram(mtcars$disp~mtcars$gear, subset = (mtcars$am == 0),
xlab = "gear", ylab = "disp", main = "Automatic")
# two way anova
# Variance in mean within group and between group
hist(mtcars$disp~mtcars$gear, subset = (mtcars$am == 0),
xlab = "gear", ylab = "disp", main = "Automatic")
?histogram
?hist
aov2 <- aov(mtcars$disp~factor(mtcars$gear) *
factor(mtcars$am))
summary(aov2)
# two way anova
# Variance in mean within group and between group
# For automatic transmission
hist(mtcars$disp[mtcars$am == 0] ~ mtcars$gear[mtcars$am == 0],
xlab = "Gear", ylab = "Disp", main = "Automatic Transmission",
col = "lightblue", border = "black")
# two way anova
# Variance in mean within group and between group
# For automatic transmission
# For automatic transmission
hist(mtcars$disp[mtcars$am == 0],
xlab = "Disp", ylab = "Frequency", main = "Automatic Transmission",
col = "lightblue", border = "black", breaks = 10)
# two way anova
# Variance in mean within group and between group
# For automatic transmission
# For automatic transmission
hist(mtcars$disp[mtcars$am == 0],
xlab = "Disp", ylab = "Frequency", main = "Automatic Transmission",
col = "lightblue", border = "black", breaks = 10)
# For manual transmission
hist(mtcars$disp[mtcars$am == 1],
xlab = "Disp", ylab = "Frequency", main = "Manual Transmission",
col = "lightgreen", border = "black", breaks = 10)
aov2 <- aov(mtcars$disp~factor(mtcars$gear) *
factor(mtcars$am))
summary(aov2)
head(mtcars)
aov1 <- aov(mpg ~ factor(gear), data=mtcars)
summary(aov1)
# two way anova
aov2 <- aov(mgp ~ factor(gear) *
factor(am),data=mtcars)
summary(aov2)
# two way anova
aov2 <- aov(mpg ~ factor(gear) *
factor(am),data=mtcars)
summary(aov2)
# two way anova
aov2 <- aov(mpg ~ factor(gear) * factor(am),data=mtcars)
summary(aov2)
############ LDA
library(MASS)
############ LDA
library(MASS)
set.seed(123)
n <- 100
mu1 <- c(1, 2)
mu2 <- c(5, 6)
sigma <- matrix(c(1, 0.5, 0.5, 1), nrow = 2)
class1 <- mvrnorm(n, mu = mu1, Sigma = sigma)
class2 <- mvrnorm(n, mu = mu2, Sigma = sigma)
data <- rbind(class1, class2)
labels <- factor(c(rep(0, n), rep(1, n)))
df <- data.frame(data, class = labels)
names(df) <- c("X1", "X2", "Class")
set.seed(123)
train_indices <- sample(1:nrow(df), size = 0.7 * nrow(df))
trainData <- df[train_indices, ]
testData <- df[-train_indices, ]
lda_model <- lda(Class ~., data = trainData)
lda_pred <- predict(lda_model, testData)
predicted_class <- lda_pred$class
confusion_matrix <- table(predicted_class, testData$Class)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
(confusion_matrix <- table(predicted_class, testData$Class))
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
n <- 100
mu1 <- c(1, 2)
mu2 <- c(3, 4)
sigma <- matrix(c(1, 0.5, 0.5, 1), nrow = 2)
class1 <- mvrnorm(n, mu = mu1, Sigma = sigma)
class2 <- mvrnorm(n, mu = mu2, Sigma = sigma)
data <- rbind(class1, class2)
labels <- factor(c(rep(0, n), rep(1, n)))
df <- data.frame(data, class = labels)
names(df) <- c("X1", "X2", "Class")
set.seed(123)
train_indices <- sample(1:nrow(df), size = 0.7 * nrow(df))
trainData <- df[train_indices, ]
testData <- df[-train_indices, ]
lda_model <- lda(Class ~., data = trainData)
lda_pred <- predict(lda_model, testData)
predicted_class <- lda_pred$class
(confusion_matrix <- table(predicted_class, testData$Class))
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
######### Importing data
data<- read.csv('data/example_data.csv')
head(data)
View(data)
mydata <- data[,-33]
write.csv(mydata,'data/output.csv',row.names=FALSE)
######## Linear regression
?USJudgeRatings
head(USJudgeRatings)
data <- USJudgeRatings
reg1= lm(RTEN~., data)
summary(reg1)
View(reg1)
y <- data$RTEN
y_pred<- predict(reg1)
plot(y,y_pred,
xlab='actual RTEN',ylab='predicted RTEN')
abline(a = 0, b = 1, col = "red", lwd = 2, lty = 2)
?kmeans
?kmeans
############ K-means Clustering
set.seed(1)
data <- iris[,1:4]
kmeans_mdl=kmeans(data,centers = 3)
plot(data[,1:2],col=kmeans_mdl$cluster)
plot(data[,1:2],col=kmeans_mdl$cluster,pch=19)
xx=iris
View(xx)
par(mfrow=c(1,2))
plot(data[,1:2],col=iris$Species, pch=19)
############ K-means Clustering
set.seed(1)
data <- iris[,1:4]
kmeans_mdl=kmeans(data,centers = 3)
par(mfrow=c(1,2))
plot(data[,1:2],col=iris$Species, pch=19)
par(mfrow=c(1,2))
plot(data[,1:2],col=iris$Species, pch=19)
plot(data[,1:2],col=kmeans_mdl$cluster,pch=19)
colors=c('red','green','blue')
true_labels=as.numeric(iris$Species)
species_colors=c('red','green','blue')
true_labels=as.numeric(iris$Species)
cluster_labels=kmeans_mdl$cluster
par(mfrow=c(1,2))
par(mfrow=c(1,2))
plot(data[,1:2],col=species_colors[true_labels], pch=19)
par(mfrow=c(1,2))
plot(data[,1:2],col=species_colors[true_labels], pch=19)
plot(data[,1:2],col=species_colors[cluster_labels],pch=19)
############ K-means Clustering
set.seed(1)
data <- iris[,1:4]
kmeans_mdl=kmeans(data,centers = 3)
species_colors=c('red','green','blue')
true_labels=as.numeric(iris$Species)
cluster_labels=kmeans_mdl$cluster
par(mfrow=c(1,2))
plot(data[,1:2],col=species_colors[true_labels], pch=19)
plot(data[,1:2],col=species_colors[cluster_labels],pch=19)
true_labels
cluser_labels
cluster_labels
View(kmeans_mdl)
View(kmeans_mdl)
table(kmeans_mdl$cluster,iris$Species)
table(kmeans_mdl$cluster,iris$Species)
cluster_labels=kmeans_mdl$cluster
mapped_labels<- ifelse(cluster_labes==2,'setosa',
ifelse(cluster_labels==1,'versicolor','virginica'))
mapped_labels<- ifelse(cluster_labels==2,'setosa',
ifelse(cluster_labels==1,'versicolor','virginica'))
mapped_labels
############ K-means Clustering
set.seed(1)
data <- iris[,1:4]
kmeans_mdl=kmeans(data,centers = 3)
# species_colors=c('red','green','blue')
# true_labels=as.numeric(iris$Species)
# cluster_labels=kmeans_mdl$cluster
true_species=iris$Species
cluster_labels=kmeans_mdl$cluster
table(cluster_labels,true_species)
mapped_labels<- ifelse(cluster_labels==2,'setosa',
ifelse(cluster_labels==1,'versicolor','virginica'))
mapped_labels <- cluster_to_species(cluster_labels, true_species)
#mapped_labels <- cluster_to_species(cluster_labels, true_species)
mapped_labels=factor(mapped_labels,levels = levels(true_species))
par(mfrow=c(1,2))
plot(data[,1:2],col=true_species, pch=19)
plot(data[,1:2],col=true_species, pch=19)
plot(data[,1:2],col=mapped_labels,pch=19)
true_species
true_species
mapped_labels
View(reg1)
View(kmeans_mdl)
table(cluster_labels,true_species)
############ K-means Clustering
set.seed(12)
data <- iris[,1:4]
kmeans_mdl=kmeans(data,centers = 3)
# species_colors=c('red','green','blue')
# true_labels=as.numeric(iris$Species)
# cluster_labels=kmeans_mdl$cluster
true_species=iris$Species
cluster_labels=kmeans_mdl$cluster
table(cluster_labels,true_species)
mapped_labels<- ifelse(cluster_labels==2,'setosa',
ifelse(cluster_labels==1,'versicolor','virginica'))
mapped_labels
par(mfrow=c(1,2))
plot(data[,1:2],col=true_species, pch=19)
plot(data[,1:2],col=mapped_labels,pch=19)
true_labels
true_species
#mapped_labels <- cluster_to_species(cluster_labels, true_species)
mapped_labels=factor(mapped_labels,levels = levels(true_species))
mapped_labels
par(mfrow=c(1,2))
plot(data[,1:2],col=true_species, pch=19)
plot(data[,1:2],col=mapped_labels,pch=19)
############ K-means Clustering
set.seed(12)
data <- iris[,1:4]
kmeans_mdl=kmeans(data,centers = 3)
# species_colors=c('red','green','blue')
# true_labels=as.numeric(iris$Species)
# cluster_labels=kmeans_mdl$cluster
true_species=iris$Species
cluster_labels=kmeans_mdl$cluster
table(cluster_labels,true_species)
mapped_labels<- ifelse(cluster_labels==2,'setosa',
ifelse(cluster_labels==1,'versicolor','virginica'))
mapped_labels=factor(mapped_labels,levels = levels(true_species))
par(mfrow=c(1,2))
plot(data[,1:2],col=true_species, pch=19)
plot(data[,1:2],col=mapped_labels,pch=19)
par(mfrow=c(1,1))
par(mfrow=c(1,1))
?mtcars
head(mtcars)
dim(mtcars)
######### correlation andheatmap
corr <-cor(mtcars)
heatmap(corr, main = "Correlation Heatmap", col = colorRampPalette(c("blue", "white", "red"))(100))
######### correlation andheatmap
corr <-cor(mtcars)
heatmap(corr, main = "Correlation Heatmap", col = colorRampPalette(c("blue", "white", "red"))(100))
library(ggplot)
# Load the package
library(pheatmap)
# Load the package
library(pheatmap)
# Plot
pheatmap(cor(mtcars),
color = colorRampPalette(c("blue", "white", "red"))(100),
main = "Correlation Heatmap")
######### correlation andheatmap
corr <-cor(mtcars)
heatmap(corr, main = "Correlation Heatmap", col = colorRampPalette(c("blue", "white", "red"))(100))
ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +
geom_boxplot() +
theme_minimal()
library(ggplot2)
ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +
geom_boxplot() +
theme_minimal()
## boxpot with ggplot2
ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +
geom_boxplot() +
theme_minimal()
### vectors and basic operations
v= c(10,20,30,40)
is.vector(v)
mean(v)
sum(v)
length(v)
### vectors and basic operations
v= c(10,20,30,40,50)
is.vector(v)
mean(v)
sum(v)
length(v)
v1=v[1:3]
print(v1)
u = v[v>20]
print(u)
## matrix
m1=matrix(c(1,2,3,4), nrow=2,byrow=TRUE)
## data frame
vNumeric <- c(1,2,3)
vCharacter <- c('a','b','c')
vLogical <- c(T,F,T)
dfa <- cbind(vNumeric,vCharacter,vLogical)
df= as.data.frame(dfa)
head(df)
name <- c("Rajiv", "Sandip", "Somnath", "Goutam")
age <- c(25, 30, 22, 28)
score <- c(90, 85, 88, 76)
df <- data.frame(name, age, score)
print(df)
head(df)
str(df)
summary(df)
df$name
df[1, ]
df[, 2]
df[2:3, c("name", "score")]
df$passed <- df$score >= 80
print(df)
result <- df$score>=80
df$passed <- reslt
df$passed <- result
print(df)
# remove a column
df$age <- NULL
print(df)
# rename a column
names(df)[names(df) == "score"] <- "final_score"
print(df)
# sort rows
df[order(df$final_score), ]# Ascending
df[order(-df$final_score), ]# Descending
aggregate(final_score ~ passed, data = df, mean)
## merged two data frames
df1 <- data.frame(id = c(1, 2), score = c(80, 90))
print(df)
print(df1)
df2 <- data.frame(id = c(1, 2), grade = c("A", "B"))
print(df2)
merged_df <- merge(df1, df2, by = "id")
print(merged_df)
colnames(merged_df)
rownames(merged_df)
nrows(merged_df)
dim(merged_df)
length(merged_df)
####### DATA TYPES
n1 <- 15
typeof(n1)
n2 <- 1.5
typeof(n2)
c1 <- 'c'
typeof(c1)
c2 <- 'a string'
typeof(c2)
l1 <- TRUE
typeof(l1)
### vectors and basic operations
v= c(10,20,30,40,50)
xx=c(2,3,4,'c',TRUE)
print(xx)
v=c(2,3,4,5,'hello',TRUE)
v=c(2,3,4,5,'hello',TRUE)
print(v)
